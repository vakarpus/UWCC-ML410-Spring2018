{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IZrAitlFLdEZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MNIST Dataset (Handwritten digist) with tf.keras\n",
    "\n",
    "On this notebook you'll learn how to train an image classifier on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) - the \"hello world\" of computer vision: loading the data, building and training a model, calculating the accuracy, and making predictions. Let's proceed with checking the TensorFlow version (should be 1.8):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jSmUsjJfMEqC",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 17 22:07:40 UTC 2018\n",
      "smallDLVM1\n",
      "Collecting tensorflow==1.8.0\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/dc/464f59597a5a8282585238e6e3a7bb3770c3c1f1dc8ee72bd5be257178ec/tensorflow-1.8.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting tensorboard<1.9.0,>=1.8.0 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/59/a6/0ae6092b7542cfedba6b2a1c9b8dceaf278238c39484f3ba03b03f07803c/tensorboard-1.8.0-py3-none-any.whl\n",
      "Collecting wheel>=0.26 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/81/30/e935244ca6165187ae8be876b6316ae201b71485538ffac1d718843025a9/wheel-0.31.1-py2.py3-none-any.whl\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==1.8.0)\n",
      "Collecting astor>=0.6.0 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/b2/91/cc9805f1ff7b49f620136b3a7ca26f6a1be2ed424606804b0fbcf499f712/astor-0.6.2-py2.py3-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow==1.8.0)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow==1.8.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/ff/f118147fd7a8d2d441d15e1cb7fefb2c1981586e24ef3a7d8a742535b085/grpcio-1.12.0-cp35-cp35m-manylinux1_x86_64.whl (9.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 9.0MB 7.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.13.3 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/61/11b05cc37ccdaabad89f04dbdc2a02905cf6de6f9b05816dba843beed328/numpy-1.14.3-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting protobuf>=3.4.0 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/5b/c3/9b947e301e19bea75dc8c1fd3710eed5d2b31aa13ae13d5e38e891f784cc/protobuf-3.5.2.post1-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting six>=1.10.0 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.1.6 (from tensorflow==1.8.0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/69/6c86a51c6cf5ad6f09a54c9a7aae09850166af8d99cf1418e9ea9250baca/absl-py-0.2.1.tar.gz (81kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 36.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl\n",
      "Collecting bleach==1.5.0 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
      "Collecting html5lib==0.9999999 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0)\n",
      "Collecting werkzeug>=0.11.10 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl\n",
      "Collecting setuptools (from protobuf>=3.4.0->tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: absl-py\n",
      "  Running setup.py bdist_wheel for absl-py ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/vadim/.cache/pip/wheels/84/69/e0/6f4b789daf6cae7e70e5fda095603c7746cdc1a6013303c7ff\n",
      "Successfully built absl-py\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-advisor~=1.0, but you'll have azure-mgmt-advisor 0.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-batch~=5.0, but you'll have azure-mgmt-batch 4.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-cdn~=2.0, but you'll have azure-mgmt-cdn 0.30.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-cognitiveservices~=2.0, but you'll have azure-mgmt-cognitiveservices 1.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-consumption~=2.0, but you'll have azure-mgmt-consumption 0.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-containerinstance~=0.3.1, but you'll have azure-mgmt-containerinstance 0.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-containerservice~=3.0, but you'll have azure-mgmt-containerservice 2.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-cosmosdb~=0.3.1, but you'll have azure-mgmt-cosmosdb 0.2.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-datalake-analytics~=0.3.0, but you'll have azure-mgmt-datalake-analytics 0.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-datalake-store~=0.3.0, but you'll have azure-mgmt-datalake-store 0.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-devtestlabs~=2.1, but you'll have azure-mgmt-devtestlabs 2.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-eventgrid~=0.4.0, but you'll have azure-mgmt-eventgrid 0.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-monitor~=0.4.0, but you'll have azure-mgmt-monitor 0.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-network~=1.7, but you'll have azure-mgmt-network 1.5.0rc3 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-recoveryservices~=0.2.0, but you'll have azure-mgmt-recoveryservices 0.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-redis~=5.0, but you'll have azure-mgmt-redis 4.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-sql~=0.8.5, but you'll have azure-mgmt-sql 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-storage~=1.5, but you'll have azure-mgmt-storage 1.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-batch-extensions 1.0.1 has requirement azure-storage<0.35,>=0.32, but you'll have azure-storage 0.36.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-cosmosdb-table 1.0.1 has requirement azure-storage-common<0.38.0,>=0.37.1, but you'll have azure-storage-common 1.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure 3.0.0 has requirement azure-datalake-store~=0.0.18, but you'll have azure-datalake-store 0.0.17 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure 3.0.0 has requirement azure-graphrbac~=0.40.0, but you'll have azure-graphrbac 0.31.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure 3.0.0 has requirement azure-servicefabric~=6.1.2.9, but you'll have azure-servicefabric 5.6.130 which is incompatible.\u001b[0m\n",
      "Installing collected packages: markdown, six, html5lib, bleach, setuptools, protobuf, werkzeug, wheel, numpy, tensorboard, termcolor, astor, gast, grpcio, absl-py, tensorflow\n",
      "\u001b[31mCould not install packages due to an EnvironmentError: [Errno 1] Operation not permitted\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n",
      "1.8.0\n"
     ]
    }
   ],
   "source": [
    "!date\n",
    "!hostname\n",
    "!pip install --ignore-installed --upgrade tensorflow==1.8.0\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "# or\n",
    "print(tf.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B8Lhscw0NDln",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 1. Downloading the dataset\n",
    "\n",
    "The MNIST dataset contains 60'000 grayscale images in training dataset and 10'000 grayscale images in testing dataset of handwritten digits. They will be downloaded automatically using ```tf.keras.datasets.mnist``` functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FKiwTuT-NE6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n",
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eEFU58MaNPpk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 2. Visualizing the data\n",
    "Let's look at the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "AwxNOsCMNNGd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0937b0bcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "i = random.randint(0, 100)\n",
    "\n",
    "print(\"Label: %s\" % train_labels[i])\n",
    "plt.imshow(train_images[i], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e2n2NVdKNk5i",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 3. Understanding the data layout\n",
    "\n",
    "We are given dataset as a list of 2D grayscale 28 by 28 images. So, it is a 3-D array of integer values that is of shape (*N*, 28, 28), where *N* is the number of images in the training or test set. The labels are 1-D array of the integer values of each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "TTj2ZWMBN24i",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  83  91 143 255 190  91  50   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   9  49 180 246 253 253 253 253 253 220 154  17   3   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  46 107 178 253 253 253 253 253 253 253 253 253 253 253 126  45   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 107 253 253 253 253 223 220 220 220 220 245 253 253 253 253 106   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 107 173 253 229 129  12   0   0   0   0 110 253 253 253 253 106   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  17  14  40  32   0   0   0   0   0   0  57 253 253 253 242  85   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5 139 224 253 253 253 105   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  65 178 253 253 253 253 219  24   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  97 250 253 253 253 253 127  47   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  46 125 250 253 253 253 245 171  33   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   5  41 217 253 253 250 245 245 115   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 124 253 253 253 192 105   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  11  47 220 253 253 188  25   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 107 253 253 253 189  13   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  41 225 253 253 186  22   0   0   0   0   0  31  42 174 205 205 205 193  58   0   0   0]\n",
      " [  0   0   0   0   0  48 218 253 253 253 150  59   0   0 128 131 131 222 253 253 253 253 253  94   0   0   0   0]\n",
      " [  0   0   0   0   0  12 152 253 253 253 253 236 222 222 252 253 253 253 253 253 253 253 253 122   0   0   0   0]\n",
      " [  0   0   0   0   0   0   7 167 253 253 253 253 253 253 253 253 253 253 253 253 253 124 106   7   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  76 188 253 253 253 253 253 253 253 224  57  15  15  15   2   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  12  89 121 253 253 151  89  89  55   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "#np.set_printoptions(precision=2)\n",
    "np.set_printoptions(linewidth=1000)\n",
    "print(train_images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eo_cZXaqODnZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 4. Reformating the images\n",
    "\n",
    "For our model (and for our own convenience) let's modify the layout of our data from 28*28 2D representation to 1D 784 (= 28 x 28) array because we plan to use fully-connected neural network as our model and convert ```integer``` grayscale intensity to ```float``` format by dividing element-wise everything my 255 (the highest intensity) - rescaling these intensities from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "OgnV5FJjP5Vz"
   },
   "outputs": [],
   "source": [
    "TRAINING_SIZE = len(train_images)\n",
    "TEST_SIZE = len(test_images)\n",
    "\n",
    "# Reshape from (N, 28, 28) to (N, 784)\n",
    "train_images = np.reshape(train_images, (TRAINING_SIZE, 784))\n",
    "test_images = np.reshape(test_images, (TEST_SIZE, 784))\n",
    "\n",
    "# Convert the array to float32 as opposed to uint8\n",
    "train_images = train_images.astype(np.float32)\n",
    "test_images = test_images.astype(np.float32)\n",
    "\n",
    "# Convert the pixel values from integers between 0 and 255 to floats between 0 and 1\n",
    "train_images /= 255\n",
    "test_images /=  255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's check the layout again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(60000,)\n",
      "[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.3 0.4 0.6 1.  0.7 0.4 0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.7 1.  1.  1.  1.  1.  1.  0.9 0.6 0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.2 0.4 0.7 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.5 0.2 0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.4 1.  1.  1.  1.  0.9 0.9 0.9 0.9 0.9 1.  1.  1.  1.  1.  0.4 0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.4 0.7 1.  0.9 0.5 0.  0.  0.  0.  0.  0.4 1.  1.  1.  1.  0.4 0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.1 0.1 0.2 0.1 0.  0.  0.  0.  0.  0.  0.2 1.  1.  1.  0.9 0.3 0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 0.9 1.  1.  1.  0.4 0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.3 0.7 1.  1.  1.  1.  0.9 0.1 0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.4 1.  1.  1.  1.  1.  0.5 0.2 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.5 1.  1.  1.  1.  1.  0.7 0.1 0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.9 1.  1.  1.  1.  1.  0.5 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.5 1.  1.  1.  0.8 0.4 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.9 1.  1.  0.7 0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.4 1.  1.  1.  0.7 0.1 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.2 0.9 1.  1.  0.7 0.1 0.  0.  0.  0.  0.  0.1 0.2 0.7 0.8 0.8 0.8 0.8 0.2 0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.2 0.9 1.  1.  1.  0.6 0.2 0.  0.  0.5 0.5 0.5 0.9 1.  1.  1.  1.  1.  0.4 0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.6 1.  1.  1.  1.  0.9 0.9 0.9 1.  1.  1.  1.  1.  1.  1.  1.  1.  0.5 0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.7 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.5 0.4 0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.3 0.7 1.  1.  1.  1.  1.  1.  1.  0.9 0.2 0.1 0.1 0.1 0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.3 0.5 1.  1.  0.6 0.3 0.3 0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "\n",
    "np.set_printoptions(precision=1)\n",
    "np.set_printoptions(linewidth=4*29)\n",
    "print(train_images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GI25z0StQH-P",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 5. Reformating the labels\n",
    "\n",
    "Next, we want to convert the labels from an integer format (e.g., \"2\"), to a [one hot encoding](https://en.wikipedia.org/wiki/One-hot) (e.g., \"0, 0, 1, 0, 0, 0, 0, 0, 0, 0\"). To do so, we'll use the ```tf.keras.utils.to_categorical``` [function](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "E9yrkEENQ9Vz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before 2\n",
      "After [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "NUM_DIGITS = 10\n",
    "\n",
    "print(\"Before\", train_labels[i]) # The format of the labels before conversion\n",
    "\n",
    "train_labels  = tf.keras.utils.to_categorical(train_labels, NUM_DIGITS)\n",
    "\n",
    "print(\"After\", train_labels[i]) # The format of the labels after conversion\n",
    "\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, NUM_DIGITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pjdbemHURkpv",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 6. Building the model\n",
    "\n",
    "Now, we'll create our neural network using the [Keras Sequential API](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential). \n",
    "* We will use fully-connected one-layer neural network \n",
    "* The hidden layer will have 512 units using the [ReLU](https://www.tensorflow.org/api_docs/python/tf/keras/activations/relu) activation function. \n",
    "* The output layer will have 10 units and use [softmax](https://www.tensorflow.org/api_docs/python/tf/keras/activations/softmax) function. \n",
    "* Notice, we specify the input shape on the first layer. If you add subsequent layers, this is not required. \n",
    "* We will use the [categorical crossentropy](https://www.tensorflow.org/api_docs/python/tf/keras/losses/categorical_crossentropy) loss function, and the [RMSProp](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop) optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mNscbvHkUrMc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "# We will now compile and print out a summary of our model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Amazing article about Optimizers: http://ruder.io/optimizing-gradient-descent/ by Sebastian Ruder\n",
    "\n",
    "| Optimizations on loss surface contours | Optimization on saddle point |\n",
    "| ---- |------|\n",
    "|   <img src=images/contours_evaluation_optimizers.gif style=\"width: 400px;\"/>  | <img src=images/saddle_point_evaluation_optimizers.gif style=\"width: 400px;\"/>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 7. Visualizing model with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('./tb/1')\n",
    "writer.add_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smallDLVM1\r\n"
     ]
    }
   ],
   "source": [
    "!hostname\n",
    "# Don't run on Azure Notebooks\n",
    "#!tensorboard --logdir ./tb/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running TensorBoard you should see the following graph:\n",
    "![initial graph](images/graph_init.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k3br9Yi6VuBT",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 8. Training the model\n",
    "\n",
    "Next, we will train the model by using the [fit method](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#fit) for 5 [epochs](https://www.quora.com/What-is-epochs-in-machine-learning). We will keep track of the training loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "gBs0LwqcVXx6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.2038 - acc: 0.9395\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 6s 104us/step - loss: 0.0913 - acc: 0.9736\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 6s 101us/step - loss: 0.0666 - acc: 0.9815\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.0523 - acc: 0.9857\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.0423 - acc: 0.9884\n",
      "Training time: 42.38 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "print(\"Training time: %.2f s\" % (time.time() - start) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rcYMPkwkWIPq",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 9. Testing\n",
    "Now that we have trained our model, we want to evaluate it. Sure, our model is >97% accurate on the training set, but what about on data it hasn't seen before? The test accuracy is a good metric for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "iuqDe4NiWBpU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 40us/step\n",
      "Test accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy: %.2f' % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jo-yoMwvXkw6",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Congratulations\n",
    "\n",
    "You have successfully used TensorFlow Keras to train a model on the MNIST dataset.\n",
    "Let's update TensorBoard Graph visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('./tb/1')\n",
    "writer.add_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running TensorBoard you should see the final graph:\n",
    "![final graph](images/graph_final.png)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "1-mnist-with-keras.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
