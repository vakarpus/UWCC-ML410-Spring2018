{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2-B5UZxUchfd",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MNIST with Eager Execution.\n",
    "\n",
    "* MNIST data converted to `tf.data` [Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)\n",
    "* This enables convenient data manipulation: parallel reads, prefetching, batching, shuffling, etc\n",
    "* Learn more about `tf.data`: https://www.tensorflow.org/programmers_guide/datasets\n",
    "\n",
    "Code is similar to the previous notebook with a few modifications:\n",
    "\n",
    "1. Instead of using `model.fit`, we use `model.train_on_batch` to demonstrate batch iteration over the dataset. \n",
    "2. Using TensorFlow optimizer to pass to the Keras model.\n",
    "3. Using enable eager execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Eager execution\n",
    "Eager execution is a mode for running TensorFlow that works just like regular Python. https://www.tensorflow.org/programmers_guide/eager\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "902Rjd5DZroO",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 17 19:06:44 UTC 2018\n",
      "nbserver\n",
      "Collecting tensorflow==1.8.0\n",
      "  Using cached https://files.pythonhosted.org/packages/c6/0e/8af18d9169ed4f1a1c72cd50defd95b8382a12f2cf7cb9b76ba053db79ad/tensorflow-1.8.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting protobuf>=3.4.0 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/9d/61/54c3a9cfde6ffe0ca6a1786ddb8874263f4ca32e7693ad383bd8cf935015/protobuf-3.5.2.post1-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting astor>=0.6.0 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/b2/91/cc9805f1ff7b49f620136b3a7ca26f6a1be2ed424606804b0fbcf499f712/astor-0.6.2-py2.py3-none-any.whl\n",
      "Collecting backports.weakref>=1.0rc1 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\n",
      "Collecting wheel (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/81/30/e935244ca6165187ae8be876b6316ae201b71485538ffac1d718843025a9/wheel-0.31.1-py2.py3-none-any.whl\n",
      "Collecting mock>=2.0.0 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl\n",
      "Collecting enum34>=1.1.6 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/c5/db/e56e6b4bbac7c4a06de1c50de6fe1ef3810018ae11732a50f15f62c7d050/enum34-1.1.6-py2-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow==1.8.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==1.8.0)\n",
      "Collecting absl-py>=0.1.6 (from tensorflow==1.8.0)\n",
      "Collecting six>=1.10.0 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
      "Collecting tensorboard<1.9.0,>=1.8.0 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/4d/1e/3bfb48ff165e331c0c5fdca5de79d497fa5d71f3cb2eee2733ff22e898df/tensorboard-1.8.0-py2-none-any.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/2a/d5/eb371e43d65989267a9daa90ee8f92d79b216184ea3c8cf0670e5c2388eb/grpcio-1.12.0-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting numpy>=1.13.3 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/e7/08f059a00367fd613e4f2875a16c70b6237268a1d6d166c6d36acada8301/numpy-1.14.3-cp27-cp27mu-manylinux1_x86_64.whl\n",
      "Collecting setuptools (from protobuf>=3.4.0->tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl\n",
      "Collecting funcsigs>=1; python_version < \"3.3\" (from mock>=2.0.0->tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/69/cb/f5be453359271714c01b9bd06126eaf2e368f1fddfff30818754b5ac2328/funcsigs-1.0.2-py2.py3-none-any.whl\n",
      "Collecting pbr>=0.11 (from mock>=2.0.0->tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/2d/9d/7bfab757977067556c7ca5fe437f28e8b8843c95564fca504de79df63b25/pbr-4.0.3-py2.py3-none-any.whl\n",
      "Collecting bleach==1.5.0 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
      "Collecting futures>=3.1.1; python_version < \"3\" (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/2d/99/b2c4e9d5a30f6471e410a146232b4118e697fa3ffc06d6a65efde84debd0/futures-3.2.0-py2-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl\n",
      "Collecting werkzeug>=0.11.10 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl\n",
      "Collecting html5lib==0.9999999 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0)\n",
      "\u001b[31mfastlmm 0.2.32 requires dill, which is not installed.\u001b[0m\n",
      "\u001b[31mgrin 1.2.1 requires argparse>=1.1, which is not installed.\u001b[0m\n",
      "Installing collected packages: six, setuptools, protobuf, astor, backports.weakref, wheel, funcsigs, pbr, mock, enum34, gast, termcolor, absl-py, numpy, html5lib, bleach, futures, markdown, werkzeug, tensorboard, grpcio, tensorflow\n",
      "Successfully installed absl-py-0.2.1 astor-0.6.2 backports.weakref-1.0.post1 bleach-2.0.0 enum34-1.1.6 funcsigs-1.0.2 futures-3.2.0 gast-0.2.0 grpcio-1.12.0 html5lib-0.999999999 markdown-2.6.11 mock-2.0.0 numpy-1.14.3 pbr-4.0.3 protobuf-3.5.2.post1 setuptools-39.1.0 six-1.11.0 tensorboard-1.8.0 tensorflow-1.8.0 termcolor-1.1.0 werkzeug-0.14.1 wheel-0.31.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda2_501/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "!date\n",
    "!hostname\n",
    "!pip install --ignore-installed --upgrade tensorflow==1.8.0\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Enable eager execution\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "evWlYUkYefG8",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "JA3braIeeggc"
   },
   "outputs": [],
   "source": [
    "TRAINING_SIZE = len(train_images)\n",
    "TEST_SIZE = len(test_images)\n",
    "\n",
    "# Reshape from (N, 28, 28) to (N, 784)\n",
    "train_images = np.reshape(train_images, (TRAINING_SIZE, 784))\n",
    "test_images = np.reshape(test_images, (TEST_SIZE, 784))\n",
    "\n",
    "# Convert the array to float32 as opposed to uint8\n",
    "train_images = train_images.astype(np.float32)\n",
    "test_images = test_images.astype(np.float32)\n",
    "\n",
    "# Convert the pixel values from integers between 0 and 255 to floats between 0 and 1\n",
    "train_images /= 255\n",
    "test_images /=  255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "wbwRqi0BeicT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Before', 5)\n",
      "('After', array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]))\n"
     ]
    }
   ],
   "source": [
    "NUM_DIGITS = 10\n",
    "\n",
    "print(\"Before\", train_labels[0]) # The format of the labels before conversion\n",
    "\n",
    "train_labels  = tf.keras.utils.to_categorical(train_labels, NUM_DIGITS)\n",
    "\n",
    "print(\"After\", train_labels[0]) # The format of the labels after conversion\n",
    "\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, NUM_DIGITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XFtvnaI5jU_5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Cast the labels to floats, needed later\n",
    "train_labels = train_labels.astype(np.float32)\n",
    "test_labels = test_labels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jjNr3gr3ejh2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 407,050\n",
      "Trainable params: 407,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu, input_shape=(784,)))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))\n",
    "\n",
    "\n",
    "# Create a TensorFlow optimizer, rather than using the Keras version\n",
    "# This is currently necessary when working in eager mode\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)\n",
    "\n",
    "# We will now compile and print out a summary of our model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUZPvDQYe5Xu",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 1) Create a tf.data Dataset\n",
    "\n",
    "Here, we'll use the `tf.data.Dataset` [API](https://www.tensorflow.org/api_docs/python/tf/data) to convert the Numpy arrays into a TensorFlow dataset.\n",
    "\n",
    "We will create a simple for loop that will serve as our introduction into creating custom training loops. Although this essentially does the same thing as `model.fit` it allows us to customize the overall training process and collect different metrics throughout the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "sdBd2pd_fdue"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "\n",
    "# Because tf.data may work with potentially **large** collections of data\n",
    "# we do not shuffle the entire dataset by default\n",
    "# Instead, we maintain a buffer of SHUFFLE_SIZE elements\n",
    "# and sample from there.\n",
    "SHUFFLE_SIZE = 10000 \n",
    "\n",
    "# Create the dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "dataset = dataset.shuffle(SHUFFLE_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ksAR-C6xgUu4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Step 2) Iterate over the dataset\n",
    "Here, we'll iterate over the dataset, and train our model using `model.train_on_batch`. To learn more about the elements returned from the dataset, you can print them out and try the `.numpy()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "kNgnUKPvgSCz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1\t Loss: 0.188710\tAccuracy: 0.958333\n",
      "Epoch #2\t Loss: 0.071446\tAccuracy: 0.989583\n",
      "Epoch #3\t Loss: 0.108608\tAccuracy: 0.979167\n",
      "Epoch #4\t Loss: 0.036231\tAccuracy: 0.989583\n",
      "Epoch #5\t Loss: 0.015115\tAccuracy: 1.000000\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  for images, labels in dataset:\n",
    "    train_loss, train_accuracy = model.train_on_batch(images, labels)\n",
    "  \n",
    "  # Here you can gather any metrics or adjust your training parameters\n",
    "  print('Epoch #%d\\t Loss: %.6f\\tAccuracy: %.6f' % (epoch + 1, train_loss, train_accuracy))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "tg5U3Iqkgo3J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 304us/step\n",
      "Test accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy: %.2f' % (accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fu0eSNa9kEFZ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Congratulations\n",
    "You have trained a model on MNIST using Keras, eager execution, and tf.data."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "2-mnist-with-keras-eager-and-tf-data.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
