{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1bsrXvzxBbl"
   },
   "source": [
    "# Classifying newswires with tf.keras, tf.data, and eager execution.\n",
    "\n",
    "In this lab, you'll learn how to classify newswires from the [Reuters dataset](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/reuters) into categories. This tutorial was inspired by [this one](https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/3.6-classifying-newswires.ipynb). This notebook is similar to previous one. The principal difference is here, we will explore a multiclass text classification problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fGBZG7rvwf2C",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 17 23:02:22 UTC 2018\n",
      "smallDLVM1\n",
      "Collecting tensorflow==1.8.0\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/dc/464f59597a5a8282585238e6e3a7bb3770c3c1f1dc8ee72bd5be257178ec/tensorflow-1.8.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting tensorboard<1.9.0,>=1.8.0 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/59/a6/0ae6092b7542cfedba6b2a1c9b8dceaf278238c39484f3ba03b03f07803c/tensorboard-1.8.0-py3-none-any.whl\n",
      "Collecting six>=1.10.0 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
      "Collecting astor>=0.6.0 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/b2/91/cc9805f1ff7b49f620136b3a7ca26f6a1be2ed424606804b0fbcf499f712/astor-0.6.2-py2.py3-none-any.whl\n",
      "Collecting protobuf>=3.4.0 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/5b/c3/9b947e301e19bea75dc8c1fd3710eed5d2b31aa13ae13d5e38e891f784cc/protobuf-3.5.2.post1-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting grpcio>=1.8.6 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/2c/ff/f118147fd7a8d2d441d15e1cb7fefb2c1981586e24ef3a7d8a742535b085/grpcio-1.12.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting absl-py>=0.1.6 (from tensorflow==1.8.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==1.8.0)\n",
      "Collecting wheel>=0.26 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/81/30/e935244ca6165187ae8be876b6316ae201b71485538ffac1d718843025a9/wheel-0.31.1-py2.py3-none-any.whl\n",
      "Collecting numpy>=1.13.3 (from tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/61/11b05cc37ccdaabad89f04dbdc2a02905cf6de6f9b05816dba843beed328/numpy-1.14.3-cp35-cp35m-manylinux1_x86_64.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow==1.8.0)\n",
      "Collecting bleach==1.5.0 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\n",
      "Collecting html5lib==0.9999999 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0)\n",
      "Collecting werkzeug>=0.11.10 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl\n",
      "Collecting setuptools (from protobuf>=3.4.0->tensorflow==1.8.0)\n",
      "  Using cached https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-advisor~=1.0, but you'll have azure-mgmt-advisor 0.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-batch~=5.0, but you'll have azure-mgmt-batch 4.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-cdn~=2.0, but you'll have azure-mgmt-cdn 0.30.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-cognitiveservices~=2.0, but you'll have azure-mgmt-cognitiveservices 1.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-consumption~=2.0, but you'll have azure-mgmt-consumption 0.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-containerinstance~=0.3.1, but you'll have azure-mgmt-containerinstance 0.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-containerservice~=3.0, but you'll have azure-mgmt-containerservice 2.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-cosmosdb~=0.3.1, but you'll have azure-mgmt-cosmosdb 0.2.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-datalake-analytics~=0.3.0, but you'll have azure-mgmt-datalake-analytics 0.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-datalake-store~=0.3.0, but you'll have azure-mgmt-datalake-store 0.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-devtestlabs~=2.1, but you'll have azure-mgmt-devtestlabs 2.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-eventgrid~=0.4.0, but you'll have azure-mgmt-eventgrid 0.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-monitor~=0.4.0, but you'll have azure-mgmt-monitor 0.3.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-network~=1.7, but you'll have azure-mgmt-network 1.5.0rc3 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-recoveryservices~=0.2.0, but you'll have azure-mgmt-recoveryservices 0.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-redis~=5.0, but you'll have azure-mgmt-redis 4.1.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-sql~=0.8.5, but you'll have azure-mgmt-sql 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-mgmt 2.0.0 has requirement azure-mgmt-storage~=1.5, but you'll have azure-mgmt-storage 1.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-batch-extensions 1.0.1 has requirement azure-storage<0.35,>=0.32, but you'll have azure-storage 0.36.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure 3.0.0 has requirement azure-datalake-store~=0.0.18, but you'll have azure-datalake-store 0.0.17 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure 3.0.0 has requirement azure-graphrbac~=0.40.0, but you'll have azure-graphrbac 0.31.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure 3.0.0 has requirement azure-servicefabric~=6.1.2.9, but you'll have azure-servicefabric 5.6.130 which is incompatible.\u001b[0m\n",
      "\u001b[31mazure-cosmosdb-table 1.0.1 has requirement azure-storage-common<0.38.0,>=0.37.1, but you'll have azure-storage-common 1.1.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: six, html5lib, bleach, setuptools, protobuf, wheel, numpy, werkzeug, markdown, tensorboard, astor, grpcio, absl-py, termcolor, gast, tensorflow\n",
      "\u001b[31mCould not install packages due to an EnvironmentError: [Errno 1] Operation not permitted\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "!date\n",
    "!hostname\n",
    "!pip install --ignore-installed --upgrade tensorflow==1.8.0\n",
    "import tensorflow as tf\n",
    "\n",
    "# Enable eager execution\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_39NLiiGy9ey"
   },
   "source": [
    "\n",
    "## A first look at the dataset\n",
    "\n",
    "### Step 1) Downloading the dataset\n",
    "\n",
    "The dataset consists of a set of short [newswires](https://www.google.com/search?q=what+is+a+newswire) and their corresponding topics as published by Reuters in 1986."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "F-DuuRzay9KG"
   },
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "arCrVEMGzR7t"
   },
   "source": [
    "### Step 2) Exploring the dataset \n",
    "\n",
    "There are around 46 different topics. The set is divided into 8982 training examples and 2246 test examples. Each training example is a list of words represented as integers similar to the IMDB dataset, and the labels are integers up to 46."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KL6sMDLVzNpF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "3\n",
      "8982\n",
      "2246\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])\n",
    "print(train_labels[0])\n",
    "print(len(train_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T9DdCQVQRlJQ"
   },
   "source": [
    "### Converting the integers to words\n",
    "\n",
    "We can get the dictionary from `tf.keras.datasets.reuters.get_word_index` which hashes the words to their corresponding integers. Let's try and convert a newswire from integers back into it's original text by first reversing this dictionary and then iterating over a newswire and converting the integers to strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nVdKXJ7PRmUb"
   },
   "outputs": [],
   "source": [
    "# Dictionary that hashes words to their integer\n",
    "word_to_integer = tf.keras.datasets.reuters.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "b8iedZIuRoIG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cms', 'linares', 'rule', 'lara', 'erste', 'raw', 'slumps', 'straddle', 'human', 'dogged']\n",
      "the\n",
      "of\n",
      "UNK the farmers home administration the u s agriculture department's farm lending arm could lose about seven billion dlrs in outstanding principal on its severely UNK borrowers or about one fourth of its farm loan portfolio the general accounting office gao said in remarks prepared for delivery to the senate agriculture committee brian crowley senior associate director of gao also said that a preliminary analysis of proposed changes in UNK financial eligibility standards indicated as many as one half of UNK borrowers who received new loans from the agency in 1986 would be UNK under the proposed system the agency has proposed evaluating UNK credit using a variety of financial ratios instead of relying solely on UNK ability senate agriculture committee chairman patrick leahy d vt UNK the proposed eligibility changes telling UNK administrator UNK clark at a hearing that they would mark a dramatic shift in the agency's purpose away from being farmers' lender of last resort toward becoming a big city bank but clark defended the new regulations saying the agency had a responsibility to UNK its 70 billion dlr loan portfolio in a UNK yet UNK manner crowley of gao UNK UNK arm said the proposed credit UNK system attempted to ensure that UNK would make loans only to borrowers who had a reasonable change of repaying their debt reuter 3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(list(word_to_integer.keys())[0:10])\n",
    "\n",
    "integer_to_word = dict([(value, key) for (key, value) in word_to_integer.items()])\n",
    "\n",
    "# Demonstrate how to find the word from an integer\n",
    "print(integer_to_word[1])\n",
    "print(integer_to_word[2])\n",
    "\n",
    "import random\n",
    "\n",
    "random_index = random.randint(0, 100)\n",
    "# We need to subtract 3 from the indices because 0 is \"padding\", 1 is \"start of sequence\", and 2 is \"unknown\"\n",
    "decoded_newswire = ' '.join([integer_to_word.get(i - 3, 'UNK') for i in train_data[random_index]])\n",
    "print(decoded_newswire)\n",
    "print(train_labels[random_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NZYEERu2R0y1"
   },
   "source": [
    "### Step 3) Format the data\n",
    "As before, we are going to multi-hot encode our newswire which is an array of integers into a 10,000 dimensional vector. We will place 1's in the indices of word-integers that occur in the newswire, and 0's for everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "nbTtNYCIR4hs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 10000)\n",
      "[0. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    # Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension), dtype=np.float32)\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.  # set specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "\n",
    "train_data = vectorize_sequences(train_data)\n",
    "test_data = vectorize_sequences(test_data)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKo1m1ZrSELb"
   },
   "source": [
    "### Step 4) Format the labels\n",
    "\n",
    "We will also use [tf.keras.utils.to_categorical](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) to one hot encode our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "b5Ew7zv-SJK-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "LABEL_DIMENSIONS = 46\n",
    "\n",
    "print(train_labels[0]) # Before\n",
    "train_labels  = tf.keras.utils.to_categorical(train_labels, LABEL_DIMENSIONS)\n",
    "print(train_labels[0]) # After\n",
    "\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels, LABEL_DIMENSIONS)\n",
    "\n",
    "# Needed later\n",
    "train_labels = train_labels.astype(np.float32)\n",
    "test_labels = test_labels.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mupgnRsQSa6k"
   },
   "source": [
    "### Step 5) Create the model\n",
    "\n",
    "Our model is similar to the previous notebook, modified to work for a multiclass classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VLsDpdIoSaIU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 64)                640064    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 647,214\n",
      "Trainable params: 647,214\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Create a model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu, input_shape=(10000,)))\n",
    "model.add(tf.keras.layers.Dense(64, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(LABEL_DIMENSIONS, activation=tf.nn.softmax))\n",
    "\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E0KQorztSW0n"
   },
   "source": [
    "### Step 6) Validation set\n",
    "\n",
    "As before, we want to test our model on data it hasn't seen before, but before we get our final test accuracy. Here, we'll create a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Ci6jFHB9TbWA"
   },
   "outputs": [],
   "source": [
    "VAL_SIZE = 1000\n",
    "\n",
    "val_data = train_data[:VAL_SIZE]\n",
    "partial_train_data = train_data[VAL_SIZE:]\n",
    "\n",
    "\n",
    "val_labels = train_labels[:VAL_SIZE]\n",
    "partial_train_labels = train_labels[VAL_SIZE:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CaNEaxWkTkAE"
   },
   "source": [
    "### Step 7) Create a tf.data Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Zx7aLE4vTnsS"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "TRAINING_SIZE = partial_train_labels.shape[0]\n",
    "\n",
    "training_set = tf.data.Dataset.from_tensor_slices((partial_train_data, partial_train_labels))\n",
    "training_set = training_set.shuffle(TRAINING_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W8S-IkYMTsHm"
   },
   "source": [
    "### Step 8) Training your model\n",
    "Please be patient as this step may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3OuvepxiTu7m"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 118us/step\n",
      "Epoch #1\t Training Loss: 3.81\tTraining Accuracy: 0.03\tValidation Loss: 3.81\tValidation Accuracy: 0.03\n",
      "1000/1000 [==============================] - 0s 116us/step\n",
      "Epoch #2\t Training Loss: 3.77\tTraining Accuracy: 0.10\tValidation Loss: 3.77\tValidation Accuracy: 0.15\n",
      "1000/1000 [==============================] - 0s 117us/step\n",
      "Epoch #3\t Training Loss: 3.67\tTraining Accuracy: 0.30\tValidation Loss: 3.66\tValidation Accuracy: 0.31\n",
      "1000/1000 [==============================] - 0s 116us/step\n",
      "Epoch #4\t Training Loss: 3.42\tTraining Accuracy: 0.41\tValidation Loss: 3.35\tValidation Accuracy: 0.47\n",
      "1000/1000 [==============================] - 0s 122us/step\n",
      "Epoch #5\t Training Loss: 2.79\tTraining Accuracy: 0.51\tValidation Loss: 2.74\tValidation Accuracy: 0.51\n",
      "1000/1000 [==============================] - 0s 122us/step\n",
      "Epoch #6\t Training Loss: 2.17\tTraining Accuracy: 0.54\tValidation Loss: 2.16\tValidation Accuracy: 0.53\n",
      "1000/1000 [==============================] - 0s 131us/step\n",
      "Epoch #7\t Training Loss: 1.93\tTraining Accuracy: 0.53\tValidation Loss: 1.77\tValidation Accuracy: 0.58\n",
      "1000/1000 [==============================] - 0s 119us/step\n",
      "Epoch #8\t Training Loss: 1.45\tTraining Accuracy: 0.68\tValidation Loss: 1.49\tValidation Accuracy: 0.66\n",
      "1000/1000 [==============================] - 0s 120us/step\n",
      "Epoch #9\t Training Loss: 1.23\tTraining Accuracy: 0.72\tValidation Loss: 1.30\tValidation Accuracy: 0.69\n",
      "1000/1000 [==============================] - 0s 110us/step\n",
      "Epoch #10\t Training Loss: 0.92\tTraining Accuracy: 0.80\tValidation Loss: 1.14\tValidation Accuracy: 0.73\n",
      "1000/1000 [==============================] - 0s 117us/step\n",
      "Epoch #11\t Training Loss: 0.93\tTraining Accuracy: 0.78\tValidation Loss: 1.04\tValidation Accuracy: 0.77\n",
      "1000/1000 [==============================] - 0s 121us/step\n",
      "Epoch #12\t Training Loss: 0.79\tTraining Accuracy: 0.83\tValidation Loss: 0.99\tValidation Accuracy: 0.78\n",
      "1000/1000 [==============================] - 0s 127us/step\n",
      "Epoch #13\t Training Loss: 0.62\tTraining Accuracy: 0.85\tValidation Loss: 0.91\tValidation Accuracy: 0.81\n",
      "1000/1000 [==============================] - 0s 137us/step\n",
      "Epoch #14\t Training Loss: 0.39\tTraining Accuracy: 0.93\tValidation Loss: 0.91\tValidation Accuracy: 0.80\n",
      "1000/1000 [==============================] - 0s 127us/step\n",
      "Epoch #15\t Training Loss: 0.34\tTraining Accuracy: 0.92\tValidation Loss: 0.88\tValidation Accuracy: 0.81\n",
      "1000/1000 [==============================] - 0s 115us/step\n",
      "Epoch #16\t Training Loss: 0.33\tTraining Accuracy: 0.92\tValidation Loss: 0.86\tValidation Accuracy: 0.82\n",
      "1000/1000 [==============================] - 0s 115us/step\n",
      "Epoch #17\t Training Loss: 0.26\tTraining Accuracy: 0.94\tValidation Loss: 0.87\tValidation Accuracy: 0.81\n",
      "1000/1000 [==============================] - 0s 116us/step\n",
      "Epoch #18\t Training Loss: 0.22\tTraining Accuracy: 0.94\tValidation Loss: 0.88\tValidation Accuracy: 0.82\n",
      "1000/1000 [==============================] - 0s 116us/step\n",
      "Epoch #19\t Training Loss: 0.17\tTraining Accuracy: 0.97\tValidation Loss: 0.90\tValidation Accuracy: 0.82\n",
      "1000/1000 [==============================] - 0s 114us/step\n",
      "Epoch #20\t Training Loss: 0.20\tTraining Accuracy: 0.95\tValidation Loss: 0.90\tValidation Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "# Store list of metric values for plotting later\n",
    "tr_loss_list = []\n",
    "tr_accuracy_list = []\n",
    "val_loss_list = []\n",
    "val_accuracy_list = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  for newswires, labels in training_set:\n",
    "    # Calculate training loss and accuracy\n",
    "    tr_loss, tr_accuracy = model.train_on_batch(newswires, labels)\n",
    "  \n",
    "  # Calculate validation loss and accuracy\n",
    "  val_loss, val_accuracy = model.evaluate(val_data, val_labels)\n",
    "\n",
    "  # Add to the lists\n",
    "  tr_loss_list.append(tr_loss)\n",
    "  tr_accuracy_list.append(tr_accuracy)\n",
    "  val_loss_list.append(val_loss)\n",
    "  val_accuracy_list.append(val_accuracy)\n",
    "  \n",
    "  print(('Epoch #%d\\t Training Loss: %.2f\\tTraining Accuracy: %.2f\\t'\n",
    "         'Validation Loss: %.2f\\tValidation Accuracy: %.2f')\n",
    "         % (epoch + 1, tr_loss, tr_accuracy,\n",
    "         val_loss, val_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TR0thBUhUDTb"
   },
   "source": [
    "### Step 9) Plotting your loss and accuracy\n",
    "We are going to use `matplotlib` to plot our training and validation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "FEekeJKbTqj-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6c99acd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = range(1, EPOCHS + 1)\n",
    "\n",
    "# \"bo\" specifies \"blue dot\"\n",
    "plt.plot(epochs, tr_loss_list, 'bo', label='Training loss')\n",
    "# b specifies a \"solid blue line\"\n",
    "plt.plot(epochs, val_loss_list, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XWybdzYEUE7p"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6c99acbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # Clear plot\n",
    "\n",
    "plt.plot(epochs, tr_accuracy_list, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy_list, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0UdrazksUI0_"
   },
   "source": [
    "### Step 10) Testing your model\n",
    "Now that we have successfully trained our model and our training accuracy has jumped over 90%, we need to test it. The test accuracy is a better evaluation metric for how our model will perform in the real world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "ta7jDHRwUGIa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246/2246 [==============================] - 0s 127us/step\n",
      "Test accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_data, test_labels)\n",
    "print('Test accuracy: %.2f' % (accuracy))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "4-reuters.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
